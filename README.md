# DreamSquad Challenge API ğŸš€

<div align="start">

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.121.0+-009688?logo=fastapi&logoColor=white)
![Strands Agents](https://img.shields.io/badge/Strands_Agents-1.18.0+-6f42c1)
![Ollama](https://img.shields.io/badge/Ollama-Local_LLM-green?logo=ollama)
![Docker](https://img.shields.io/badge/Dockerfile-Ready-blue?logo=docker)


Este projeto integra **FastAPI** com o **Strands Agents SDK** e **Ollama** para criar um assistente capaz de executar ferramentas matemÃ¡ticas e conversaÃ§Ã£o natural, seguindo rigorosos padrÃµes de engenharia de software.

**Destaques TÃ©cnicos:**
* ğŸ—ï¸ **Arquitetura Modular:** SeparaÃ§Ã£o clara entre Rotas, Services, Schemas e Agentes.
* ğŸ›¡ï¸ **SeguranÃ§a:** ValidaÃ§Ã£o contra *Prompt Injection*.
* ğŸš¦ **Rate Limiting:** Rate Limiting com SlowAPI (1 req/seg).
* ğŸ³ **Dockerizado:** Pronto para deploy.
* ğŸ§ª **Testes Completos** - ValidaÃ§Ã£o dos mÃ³dulos
* ğŸ­ **Easter Egg** - Descubra nos testes!

---

â€¢ [Quick Start](#-quick-start) â€¢ [API Docs](docs/API.md)

</div>

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Tecnologias](#tecnologias)
- [Quick Start](#-quick-start)
  - [PrÃ©-requisitos](#prÃ©-requisitos)
  - [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
  - [ExecuÃ§Ã£o Local](#execuÃ§Ã£o-local)
  - [ExecuÃ§Ã£o com Docker](#execuÃ§Ã£o-com-docker)
- [Testes](#-testes)
- [Troubleshooting](#troubleshooting-rÃ¡pido)

---

## ğŸ¯ VisÃ£o Geral

API REST que integra um agente de IA configurÃ¡vel com capacidades de tomada de decisÃ£o autÃ´noma:

- âœ… **Processa requisiÃ§Ãµes** via endpoints REST
- âœ… **LLM local** com Ollama 
- âœ… **Executa ferramentas** (calculadora matemÃ¡tica)
- âœ… **ValidaÃ§Ã£o de seguranÃ§a** contra prompt injection
- âœ… **Rate limiting** para proteÃ§Ã£o
- âœ… **Contexto conversacional** mantido

---

## ğŸ“š DocumentaÃ§Ã£o

| Documento | DescriÃ§Ã£o |
|-----------|-----------|
| **[API.md](docs/API.md)** | ReferÃªncia completa da API |

### DocumentaÃ§Ã£o Interativa (Recomendado)

Com a aplicaÃ§Ã£o rodando, acesse:

- **Swagger UI:** http://localhost:8000/docs

---

## ğŸ“‚ Estrutura do Projeto
```
dreamsquad_challenge/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # ğŸš€ Arquivo principal
â”‚   â”œâ”€â”€ agents/              # ğŸ¤– Agentes IA
â”‚   â”œâ”€â”€ api/routers/         # ğŸŒ Endpoints REST
â”‚   â”œâ”€â”€ core/                # âš™ï¸ ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ models/              # ğŸ“‹ Schemas Pydantic
â”‚   â”œâ”€â”€ security/            # ğŸ”’ ValidaÃ§Ãµes seguranÃ§a
â”‚   â””â”€â”€ services/            # ğŸ’¼ LÃ³gica de negÃ³cio
â”œâ”€â”€ docs/                    # ğŸ“š DocumentaÃ§Ã£o detalhada
â”œâ”€â”€ tests/                   # ğŸ§ª Testes automatizados
â”œâ”€â”€ .env.example            # Template de variÃ¡veis
â”œâ”€â”€ Dockerfile              # ConfiguraÃ§Ã£o Docker
â””â”€â”€ README.md               # Este arquivo
```

**Arquitetura em Camadas:**
```
HTTP Request â†’   API Router â†’   Service â†’      Agent â†’     Ollama
                [validaÃ§Ã£o]   [seguranÃ§a]   [tools/LLM]
```

---


## ğŸ› ï¸ Tecnologias

| Tecnologia | VersÃ£o | PropÃ³sito |
|---|---|---|
| **Python** | 3.11+ | Linguagem principal |
| **FastAPI** | â‰¥0.121.0 | Framework web |
| **Uvicorn** | â‰¥0.38.0 | Servidor |
| **Pydantic** | â‰¥2.12.0 | ValidaÃ§Ã£o de dados |
| **Strands Agents** | â‰¥1.18.0 | OrquestraÃ§Ã£o de agentes IA |
| **Strands Tools** | â‰¥0.2.16 | Ferramentas para agentes |
| **Ollama** | Latest | LLM local |
| **SlowAPI** | â‰¥0.1.9 | Rate limiting |
| **python-dotenv** | â‰¥1.2.0 | Gerenciamento de variÃ¡veis de ambiente |
| **pytest** | â‰¥9.0.0 | Framework de testes |


---

## ğŸš€ Quick Start

### PrÃ©-requisitos

- âœ… Python 3.11 ou superior
- âœ… pip (gerenciador de pacotes Python)
- âœ… Ollama instalado (veja [instalaÃ§Ã£o do Ollama](#-instalaÃ§Ã£o-do-ollama))

### InstalaÃ§Ã£o
```bash
# 1. Clonar repositÃ³rio
git clone https://github.com/caio-torres-seares/dreamsquad_challenge.git
cd dreamsquad_challenge

# 2. Criar ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# ou
.venv\Scripts\activate     # Windows

# 3. Instalar dependÃªncias
pip install -r requirements.txt

# 4. Configurar variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas configuraÃ§Ãµes
```

### ğŸ”§ ConfiguraÃ§Ã£o do Ambiente

Crie um arquivo `.env` na raiz do projeto com:

```env
# Provider LLM 
LLM_PROVIDER=ollama

# EndereÃ§o do Ollama
OLLAMA_HOST=http://localhost:11434

# Modelo baixado via 'ollama pull'
LLM_MODEL_ID=llama3.1:8b

# Limite mÃ¡ximo de caracteres permitidos no prompt
MAX_PROMPT_LENGTH=2000
```




## ğŸ¦™ ConfiguraÃ§Ã£o do Ollama
### 1. Verificar se Ollama estÃ¡ rodando
```bash
curl http://localhost:11434/api/tags
```

### 2. Baixar o modelo LLM

RecomendaÃ§Ã£o: o modelo `llama3.1:8b` apresentou o melhor equilÃ­brio entre qualidade e desempenho durante os testes deste projeto.  

- Tamanho aproximado: **4.9 GB**
- Boa qualidade de respostas
- Capaz de lidar com ferramentas (calculator) com precisÃ£o

Para mÃ¡quinas com menos RAM ou disco, uma alternativa mais leve Ã© o `llama3.2`, com aproximadamente **2.0 GB**, mantendo um desempenho "ok" para consultas gerais.

```bash
ollama pull llama3.1:8b
```
### 3. Atualizar .env
```bash
echo "LLM_MODEL_ID=llama3.1:8b" >> .env
```

---

## ğŸ–¥ï¸ ExecuÃ§Ã£o

### OpÃ§Ã£o 1: ExecuÃ§Ã£o Local (Desenvolvimento)

**âš ï¸ AtenÃ§Ã£o! Antes de tudo, garanta que o Ollama estÃ¡ rodando**
```bash
# 1. Roda o serviÃ§o ollama
ollama serve
```

```bash
# 2. Ativar ambiente virtual
.venv\Scripts\activate     # Windows

# ou

source .venv/bin/activate  # Linux/macOS


# 3. Executar aplicaÃ§Ã£o
uvicorn app.main:app --reload --host 0.0.0.0
```

A API estarÃ¡ disponÃ­vel em: **http://localhost:8000**

E a documentaÃ§Ã£o estarÃ¡ disponÃ­vel em: **http://localhost:8000/docs**

**OpÃ§Ãµes Ãºteis:**
- `--reload`: Hot reload (apenas desenvolvimento)
- `--host 0.0.0.0`: Aceita conexÃµes externas
- `--port 8000`: Permite mudar a porta padrÃ£o de execuÃ§Ã£o (8000)


**Verificar status:**
```bash
curl http://localhost:8000/health
```

---

### OpÃ§Ã£o 2: ExecuÃ§Ã£o com Docker (ProduÃ§Ã£o)

**âš ï¸ AtenÃ§Ã£o! Antes de tudo, garanta que o Ollama estÃ¡ rodando**
```bash
# 1. Roda o serviÃ§o ollama
ollama serve
```

```bash
# 2. Build da imagem
docker build -t dreamsquad-api:latest .

# 3. Executar container
docker run --name dreamsquad-chat -p 8000:8000 dreamsquad-api:latest

# 4. Verificar logs
docker logs -f dreamsquad-chat

# 5. Testar
curl http://localhost:8000/health
```


**Parar container:**
```bash
docker stop dreamsquad-api
```

**Remover container:**
```bash
docker rm dreamsquad-api
```

---

## ğŸ§ª Testes

### Executar Testes
```bash
# Com output detalhado
pytest -vs
```

### Estrutura
```
tests/
â”œâ”€â”€ conftest.py               # Fixtures compartilhadas
â”œâ”€â”€ test_api.py               # Testes de endpoints
â””â”€â”€ test_best_agent_answer.py # Testes do agente (+ easter egg!)
```

## ğŸ­ Easter Egg

Descubra o teste especial:
```bash
# Certifique-se que Ollama estÃ¡ rodando
ollama serve

# Execute com output
pytest -vs tests/test_best_agent_answer.py
```

> **Spoiler:** Ã‰ um teste tÃ©cnico vÃ¡lido que tambÃ©m deixa uma mensagem criativa! ğŸ˜‰

---


## ğŸ”§ Troubleshooting RÃ¡pido

**Erro 500 ao chamar /chat?**

Certifique-se de ter o ollama rodando
```bash
ollama serve
curl http://localhost:11434/api/tags
```

**Ollama nÃ£o conecta?**
```bash
ollama serve
curl http://localhost:11434/api/tags
```

**Modelo nÃ£o encontrado?**
```bash
ollama list
ollama pull llama3.1:8b # ou outra versÃ£o de sua escolha
```

**Docker nÃ£o acessa Ollama?**
- Use `http://host.docker.internal:11434` (Windows/macOS)
- Use `http://172.17.0.1:11434` (Linux)


---

## ğŸ“„ LicenÃ§a

Desenvolvido como case tÃ©cnico para **DreamSquad**.

---

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/caio-seares)



</div>